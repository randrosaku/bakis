{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "tf.keras.utils.disable_interactive_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = np.load(\"data/Test_clean.npy\")\n",
    "test_noisy = np.load(\"data/Test_noisy.npy\")\n",
    "\n",
    "test_clean_2 = np.load(\"data/Test_clean_2.npy\")\n",
    "test_noisy_2 = np.load(\"data/Test_noisy_2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = [test_noisy, test_clean]\n",
    "dataset_2 = [test_noisy_2, test_clean_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b40_LR00005 = load_model('models/b40-LR00005.keras')\n",
    "model_b10_LRsch = load_model('models/b10-LRsch.keras')\n",
    "model_b20_LRsch = load_model('models/b20-LRsch.keras')\n",
    "model_b40_LRsch = load_model('models/b40-LRsch.keras')\n",
    "model_b60_LRsch = load_model('models/b60-LRsch.keras')\n",
    "\n",
    "model_b20_LRsch_2 = load_model('models/b20-LRsch-e500.keras')\n",
    "model_b60_LRsch_2 = load_model('models/b60-LRsch-e500.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = [model_b40_LR00005, model_b10_LRsch, model_b20_LRsch, model_b40_LRsch, model_b60_LRsch]\n",
    "models_2 = [model_b20_LRsch_2, model_b60_LRsch_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance results\n",
      "------------------------------------------------------------------\n",
      "|   Model 1   |   Loss: 0.3064  |  Mean absolute error: 0.4022   |\n",
      "\n",
      "|   Model 2   |   Loss: 0.3063  |  Mean absolute error: 0.4021   |\n",
      "\n",
      "|   Model 3   |   Loss: 0.3063  |  Mean absolute error: 0.4021   |\n",
      "\n",
      "|   Model 4   |   Loss: 0.3044  |  Mean absolute error: 0.4006   |\n",
      "\n",
      "|   Model 5   |   Loss: 0.3050  |  Mean absolute error: 0.4009   |\n",
      "\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Model performance results\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "for idx, model in enumerate(models_1):\n",
    "    loss, mae = model.evaluate(x=dataset_1[0], y=dataset_1[1], verbose=2)\n",
    "    print(f\"|   Model {idx+1}   |   Loss: {np.round(loss, 4):.4f}  |  Mean absolute error: {np.round(mae, 4):.4f}   |\\n\");\n",
    "\n",
    "print(\"------------------------------------------------------------------\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance results pt 2\n",
      "----------------------------------------------------------------------------------\n",
      "|   Model 1   |   Dataset 1   |   Loss: 0.3066  |  Mean absolute error: 0.4023   |\n",
      "\n",
      "|   Model 1   |   Dataset 2   |   Loss: 0.3231  |  Mean absolute error: 0.3868   |\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "|   Model 2   |   Dataset 1   |   Loss: 0.3062  |  Mean absolute error: 0.4022   |\n",
      "\n",
      "|   Model 2   |   Dataset 2   |   Loss: 0.3225  |  Mean absolute error: 0.3866   |\n",
      "\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Model performance results pt 2\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "for idx, model in enumerate(models_2):\n",
    "    loss, mae = model.evaluate(x=dataset_1[0], y=dataset_1[1], verbose=2)\n",
    "    print(f\"|   Model {idx+1}   |   Dataset 1   |   Loss: {np.round(loss, 4):.4f}  |  Mean absolute error: {np.round(mae, 4):.4f}   |\\n\");\n",
    "\n",
    "    loss, mae = model.evaluate(x=dataset_2[0], y=dataset_2[1], verbose=2)\n",
    "    print(f\"|   Model {idx+1}   |   Dataset 2   |   Loss: {np.round(loss, 4):.4f}  |  Mean absolute error: {np.round(mae, 4):.4f}   |\\n\");\n",
    "    print(\"----------------------------------------------------------------------------------\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
